[사전 온라인 교육] - 데이터의 가치와 분석
1. 데이터 가치의 재발견 
  1) Edyn
    - 토양에 센서를 설치
    - 토양의 상태를 실시간으로 mobile phone으로 확인 가능 
    - 비즈니스 모델은 흔하며 수익성이 높지 않다
    - 하지만 수집한 토양의 데이터를 판매하는 식으로 비즈니스 모델을 바꾼다면 부가가치는 상상하는 것 그 이상이 될 것이다. 
  --> 즉 데이터가 가지는 가치에 대해서 생각해볼 수 있다. 
  
  2) Nest & Google 
    - Nest라고하는 Strat up을 유튜브의 인수가격의 두배를 들여 인수
    - 실내 온도조절 장치를 주력으로 삼는 기업
    - 가정용 IoT의 허브로서 삼기위해 인수 하지만 그것만으로는 M&A의 비용을 설명하기에 논리가 부족
    - 하지만 가정의 온도변화를 체크하여 데이터를 수집하기 위해서라면 설명이 가능 
   
  3) Remember & Naver
    - 네이버가 Remember라는 기업을 인수: Remember는 명함을 관리하는 작은 스타트업 (인수금액 100억) 
    - Remember가 가지고 있는 Business Card에 대한 Data를 원했다고 판단
    - Business Card에는 많은 정보가 포함되어 있고 Business Card를 주고 받는 관계에도 관심을 보였다고 할 수 있음
  
  4) Netatmo 
    - 가정의 기상청이라는 이름을 가진 IoT기업 
    - 가정에서 남자의 폐암과 여성의 폐암이 다르지 않다고 발표(주방의 조리시 발생하는 연기로 인해) 
    - 가정에서 발생하는 연기를 측정하여 알려주는 IoT제품
    - 삼성과 다이슨에 비해 성능, 가격 등에는 경쟁우위를 갖추지 못함 
    - Netatmo의 경쟁우위는 바로 가정에서 측정된 기상 정보를 웹에서 제공한다는 것이다. 
    
  5) Data & Company's Value
    - 10년전에는 제조업을 주력으로 하는 기업들이 상위기업을 차지
    - 하지만 현재는 platform과 contents를 주력으로 하는 기업들이 상위를 차지
    - 이제는 제조업도 제품 생산만을 주력으로 한다면 생존하는 것이 어려울 것이다. 
    
  6) HYPE Cycle of Gartner
    - 최근에는 HYPE Cycle에는 빅데이터라는 분야가 포함되지 않는다.
    - 그와 함께 Gartner 그룹은 빅데이터는 기업에 있어 당연한 요소 기술이므로 포함되지 않는다고 발표 
    - 그러나 IoT, 머신러닝, 딥러닝 기술 등은 HYPE Cycle은 포함되고 있다. 
    
  단순히 크기만을 가지고 빅데이터를 이야기한다면 의미가 없다. 
  빅 + 데이터 가 아닌 빅데이터로 이야기 해야한다. 


2. 빅데이터와 4차 산업혁명
  1) 생산성
    - 많은 국가들이 제조업의 르네상스를 꿈꾸며 많은 정책을 내놓고 있다. 
    - 이를 4차산업혁명, Digital Transformation, industry 4.0 등이 있다. 
    
  2) 독일의 RAMI 4.0
    - 스마트팩토리의 표준모델 
    - 현재 독일이 전 세계를 리드하고 있음 
    - First Mover로서 Benefit을 얻기 위해서는 표준화에 힘써야한다. 
    
  3) 생산의 3요소
    - 전통적인 생산의 3요소는 노동력, 자본, 지식/기술 등이었다. 
    - 과거엔 중요성이 노동 > 자본 > 지식/기술 으로 부각되었지만 현재는 지식/기술 > 자본 > 노동 순으로 부각되고 있다.. 

  4) 대량생산 
    - 산업혁명을 이야기할때 빼놓을 수 없는 주제
    - 1차: 증기기관을 이용한 대량생산, 2차: 컨베이어 벨트와 전기를 이용한 대량생산, 3차: 인터넷을 이용한 대량생산
    - 4차산업혁명도 대량생산을 포함하지만 맞춤형 생산까지 만족하는 생산체계일 것이다. 
    
  5) Data, Software & Machine 
    - 기존의 3차 산업까지는 Machine과 Software을 중심으로 Data가 생산
    - 4차 산업에서는 Data를 통해 Software과 Machine을 생산
    - 그 대표적인 예가 자율주행차 (도로 시험을 통해 데이터를 확보하고 인공지능 모델을 완성시킴) 
    
  전체 Data중 80%가 Garbage Data로 버려지며 20%만 사용된다. 
  그러나 20%의 데이터로는 문제를 해결할 수 없다. 
  그래서 80%의 데이터마저 이용하여 문제를 해결하려 함
    
3. 빅데이터의 이해 
  1) 빅데이터 정의
    - 대량의 데이터 분석을 통해, 일반적으로 불 수 없었던 새로운 사실, 패턴, 법칙을 발견하여 새로운 비즈니스 가치를 창출하는 기법 
    - 기존의 분석의 절차나 방법들을 모두 포함하지만 모집단을 분석할 수 있는 방법이 안정되어 전체를 대상으로 진행하는 분석이 가능하게 됨 
  
  2) 통찰에서 예측까지 
    a. Hindsight: 조직별 정형 데이터를 취합/분석하여 리포팅
    b. Insight: 전사 차원의 정형데이터를 Mining과 통계기법으로 분석하여 리포팅하고 insight를 찾아내 Business 의사결정에 활용 
    c. Foresight: 사내외 모든 데이터를 활용하고 Advanced Analysis를 이용하여 예측/최적화 모델을 제시함으로써 Business 의사결정을 지원   

  3) 빅데이터의 특성
    - 다양성 (Variety)
    - 크기 (Volume)
    - 속도 (Velocity)
    - 그러나 결과적으로는 기업에서 가치(Value)를 창출
    - 과거에 풀지못한 고질적인 문제를 빅데이터를 통해 풀려고함 (그러므로 기업에서 내려오는 과제는 매우 어렵다) 
    - 분산병렬처리(Hadoop, Mapreduce) 
    
  4) 저장 기술
    - 나눠서 많이 저장하고, 동시에 빠르게 처리하는 솔루션 
    - 증가하는 데이터를 처리하는 것은 매우 어렵고 가용성을 확보하기 위해서는 기존의 방식(DB)으로는 한계가 있다.
    - 이러한 문제를 해결하기 위해 GFS, 아파치, Hadoop 등이 등장 
    
  5) Hadoop
    - 대량의 데이터가 들어오면 작은 데이터로 분할하여 여러 컴퓨터(Node)에 분산하여 저장 
    - 기존의 방식보다 Scale Out 방식이 뛰어나다
  
  6) 비정형 분석
    - Text 등의 방대한 비정형 데이터를 빠른 속도로 분석 
    - 인터넷, SNS 데이터 폭발적 증가 (80% 이상이 Text 데이터) 
    - 컴퓨터를 활용한 Real Time 분석 (컴퓨터는 하루에 2400만장을 처리 가능) 

4. Data Scientist와 Citizen Data Scientist 
  내용 생략 

5. 빅데이터 분석 방법론
  1) 방법론
    - 개개인의 역량과 경험에 의존하지 않고 누가 수행하던 "일정수준의 질과 양"이 보장될 수 있는 체계(시스템)를 의미
    - 방법론이 없이 성공할 수 있으나 일회성일 경우가 대부분이며 성공요인에 대해 알 수 없다
    - 절차와 방법, 도구와 기법, 산출물로 구성되어 있음
    
  2) 방법론은 어떤 과정을 거칠까?
    - 4단계의 순환 사이클을 거침
    - 공유화 -> 문서화 -> 지식화 -> 내면화의 선순환 과정을 거친다. 
  
  3) 방법론의 모델
    - 폭포수(waterfall) 모델
      a) 복잡성이 낮고 사례가 많음
      b) 그러나 단계별 접근방법으로 각 단계를 완벽히 완료해야 후에 문제가 안생김 
      
    - 나선형(spiral) 모델 
      a) 요구사항 충족에는 장점이 큰 모델
      b) 그러나 철저한 관리가 없다면 완성에 대한 부담이 마지막 단계에 몰리게됨
      
    - 프로토타입(prototype) 모델
    
  4) 데이터 분석을 위한 방법론
    - KDD
      Selection - Pre Processing - Transformation - Data mining - Interpretation/Evalutaion 의 과정으로 진행 
      
    - SEMMA (SAS에서 사용하는 방법론)
      Sample - Exploration - Modification - Modeling - Assessment 
      
    - CRISP-DM (가장 많이 사용되는 방법론)
      a) Business understanding - Data understanding - Data Preparation - Modeling - Evaluation - Deployment 
      b) Business data와 도메인 지식에 대한 강조
  
    - 참조 모델 
      planning - data preparing - data analyzing - system developing - deploying 
      
6. 분석기획 및 데이터 수집 단계 
  내용생략
  
7. 빅데이터 분석 단계 
  
  1) Descriptive analytics (기술적 분석)
    - 데이터를 탐색하여 데이터에서 발생한 사건을 관찰하는 분석
  2) Diagnostic analytics (진단 분석)
    - 왜 이러한 사건이 발생하였는가? -> 원인분석
    - 보통 데이터 분석의 진행 과정
  3) Predictive analytics (예측 분석)
    - 분석의 의미를 갖는 단계 
    - 앞으로 어떤 일이 벌어질지에 대해 예측
  4) Prescirptive 
    - 해결 방안 도출
  
  다만, 3~4번을 안한다고 해서 Data analytics가 아닌 것은 아니다 (단지 도전일뿐)
  1~2번만으로도 충분한 고객 니즈가 있다면 그것은 훌륭한 Data analytics
  
  5) 일반적인 데이터 분석의 과정 
    - Prepare Dataset -> Text Analysis -> EDA -> Modeling -> Model Assess -> Model Deployment
  
  6) 데이터 분석에 사용되는 도구
    - 대부분은 Excel을 사용하지만 R의 사용빈도가 35.3%로 꽤 높은 편이며 최근 Ptython의 약진이 돋보인다. 

  7) 무료와 오픈소스의 차이 
    - 무료는 자유롭게 활용할 수 있으나 오픈소스는 라이선스 정책에 따르는 것을 의미
    - 이는 일정한 기준에 맞을때는 자신이 만든 것을 공개해야할 수 있다. 
    
  8) 시각화의 중요성
    - 나폴레옹 사례
    - 나이팅 게일의 사례 
    
  9) 시각화 방법
    - 시간 시각화: 막대그래프, 누적 막대 그래프, 점 그래프
    - 분포 시각화: 파이 차트, 원형 차트, 트리맵, 누적 연속 그래프
    - 관계 시각화: 스케터 플롯(산점도), 버블 차트, 히스토그램
    - 비교 시각화: 히트맵, 스타 차트, 평행 좌표계, 다차원 척도법
    - 공간 시각화: 지도맵핑
    
  10) 정보 디자인 
    - 데이터 시각화 -> 정보형 메세지 (빅데이터 시각화)
    - 정보 시각화 -> 정보형 메세지 (빅데이터 시각화) 
    - 인포그래픽 -> 설득형 메세지: 빅데이터 분석에서 사용하는 것을 지양한다. 
  
  11) Machine Learning (기계학습) 
    - 컴퓨터가 경험적 데이터에 기반하여 그 행동을 진화시키는 알고리즘의 설계 및 개발을 다루는 과학 
    - 머신러닝이 의미있게 다가오는 이유는
    - 지도학습(supervised Learning): Label을 가지고 있는 데이터를 입력으로 받아 출력으로 사상하는 함수를 학습
    - 비지도 학습(Unsupervised Learning): Label이 없는 데이터에서 패턴을 학습
    - 강화학습(reinforcement learning): Reward와 Penalty를 부여함으로써 학습, 강화 이전의 동작 중 그 강화에 가장 관련이 있는 것을 결정하는 것이 핵심
    - 반지도학습(Semi-supervised Learning): Label이 있는 작은 표본을 기초로 Label이 주어지지 않는 다수의 표본으로부터 학습
    
  12) Supervised Learning 
    - 분류 알고리즘: SVM, K-NN, Naive Bayes, Decision Tree, Random Forest, Logistic Regression, Neural Network
    - 회귀 알고리즘: Linear Regression, K-NN, SVM, Random Forest
    - 다만 분류와 회귀 알고리즘을 나누는 것은 무의미하다 Feature에 따라 다르기 때문에 
  
  13) Unsupervised Learning 
    - K-means, Clustering, PCA, Neural Network, 연관관계분석 등 
  
8. 시스템화 및 전개 단계 
  내용 생략

9. 빅데이터 프로젝트의 CSF
  내용 생략
  
10 - R 설치 및 기초 프로그램
  생략  
